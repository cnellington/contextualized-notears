{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Caleb Ellington\n",
    "C-NOTEARS hack\n",
    "10/2/20\n",
    "\n",
    "This is a hacked-together proof-of-concept for the contextualized no-tears method.\n",
    "A list of all the bad design choices is kept below\n",
    "==================================================\n",
    "\n",
    "- batchsize limited to 1 for training reasons\n",
    "- TODO: Make Xn the same shape as Wn to allow easy model.fit\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtypes (1000, 3), W_n (1000, 10, 10), e_n (1000, 50, 1), X_n (1000, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "!python dataloader.py\n",
    "\n",
    "archz = np.load('outputs/archetypes.npz')\n",
    "W_k = archz['W_k']\n",
    "e_k = archz['e_k']\n",
    "samplez = np.load('outputs/samples.npz')\n",
    "subtypes = samplez['subtypes']\n",
    "W_n = samplez['W_n']\n",
    "e_n = samplez['e_n'][:,:,np.newaxis]\n",
    "X_n = samplez['X_n']\n",
    "print(f\"subtypes {subtypes.shape}, W_n {W_n.shape}, e_n {e_n.shape}, X_n {X_n.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 1000, d 10, xn 10, cn 50, k 3\n"
     ]
    }
   ],
   "source": [
    "n, d, _ = W_n.shape\n",
    "xn = X_n.shape[1]\n",
    "cn = e_n.shape[1]\n",
    "k = subtypes.shape[1]\n",
    "batch_size = 1\n",
    "epochs = 100\n",
    "encoder_input_shape = (cn, 1)\n",
    "encoder_output_shape = (k,)\n",
    "dict_output_shape = (d, d)\n",
    "tf_dtype = tf.dtypes.float32\n",
    "\n",
    "print(f\"n {n}, d {d}, xn {xn}, cn {cn}, k {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = tf.keras.layers.Input(\n",
    "    shape=encoder_input_shape, dtype=tf_dtype, name=\"C\"\n",
    ")\n",
    "\n",
    "encoder = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(np.prod(encoder_output_shape), activation='softmax'),\n",
    "])\n",
    "encodings = encoder(context)\n",
    "# encodings = tf.keras.layers.Lambda(lambda x: x, name=\"E\")(encodings)\n",
    "\n",
    "class Explainer(tf.keras.layers.Layer):\n",
    "    def __init__(self, archetype_shape):\n",
    "        super(Explainer, self).__init__()\n",
    "        self.archetypes = self.add_weight(\"archetypes\", \n",
    "                                          shape=archetype_shape)\n",
    "        self.k, self.d, _ = archetype_shape\n",
    "        \n",
    "    def build(self, input_shapes):\n",
    "        pass\n",
    "        \n",
    "    def call(self, subtype):\n",
    "        tiled = tf.tile(subtype, (self.d*self.d, 1))\n",
    "        transposed = tf.transpose(tiled)\n",
    "        weights = tf.reshape(transposed, (subtype.shape[1], self.d, self.d))\n",
    "        result = tf.math.reduce_sum(tf.math.multiply(weights, self.archetypes), axis=0)\n",
    "        return result\n",
    "        \n",
    "explainer = Explainer(W_k.shape)\n",
    "outputs = explainer(encodings)\n",
    "# outputs = tf.keras.layers.Reshape(dict_output_shape, name=\"Y\")(network)\n",
    "model = tf.keras.models.Model(inputs=context, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 987us/step - loss: 492.2352 - accuracy: 0.09850s - loss: 686.7396 - \n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 979us/step - loss: 275.6503 - accuracy: 0.1034\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 870us/step - loss: 255.4788 - accuracy: 0.1013\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 889us/step - loss: 252.1045 - accuracy: 0.1007\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 872us/step - loss: 241.9601 - accuracy: 0.0935\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 916us/step - loss: 240.1981 - accuracy: 0.1019\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 932us/step - loss: 237.3702 - accuracy: 0.1015\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 928us/step - loss: 233.8383 - accuracy: 0.1005\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 984us/step - loss: 233.9554 - accuracy: 0.1036\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 927us/step - loss: 233.1738 - accuracy: 0.1042\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 971us/step - loss: 234.3396 - accuracy: 0.1047\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 987us/step - loss: 236.8634 - accuracy: 0.1020\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 969us/step - loss: 237.1330 - accuracy: 0.1020\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.7973 - accuracy: 0.1060\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 236.8285 - accuracy: 0.1100\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.6825 - accuracy: 0.1071\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 241.1757 - accuracy: 0.0991\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.3213 - accuracy: 0.1019\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.7337 - accuracy: 0.1016\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.1118 - accuracy: 0.1014\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.3906 - accuracy: 0.1040\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.3767 - accuracy: 0.1019\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.3590 - accuracy: 0.1066\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.2411 - accuracy: 0.1025\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.8732 - accuracy: 0.0994\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.8406 - accuracy: 0.1116\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.3047 - accuracy: 0.1040\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.0821 - accuracy: 0.0967\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.1132 - accuracy: 0.1015\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 236.3734 - accuracy: 0.0984\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.1506 - accuracy: 0.1071\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 236.3666 - accuracy: 0.1015\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.2587 - accuracy: 0.1054\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.3006 - accuracy: 0.0949\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.4994 - accuracy: 0.1030\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.8051 - accuracy: 0.1034\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.1132 - accuracy: 0.0988\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.4117 - accuracy: 0.0996\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.8635 - accuracy: 0.1061\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.8323 - accuracy: 0.1086\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.2169 - accuracy: 0.0986\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.3042 - accuracy: 0.0991\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.4868 - accuracy: 0.0989\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 240.0559 - accuracy: 0.1004\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.7010 - accuracy: 0.1040\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 236.5957 - accuracy: 0.1020\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.8319 - accuracy: 0.1040\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.8458 - accuracy: 0.1066\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.0450 - accuracy: 0.0959\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 240.4131 - accuracy: 0.1007\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 235.2964 - accuracy: 0.1018\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.5305 - accuracy: 0.1051\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.4075 - accuracy: 0.0986\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.0160 - accuracy: 0.1045\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.9859 - accuracy: 0.1021\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.6471 - accuracy: 0.1050\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.1093 - accuracy: 0.1020\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 238.2806 - accuracy: 0.1080\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.1354 - accuracy: 0.1034\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 2s 2ms/step - loss: 241.0330 - accuracy: 0.1004\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.5586 - accuracy: 0.1019\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.2722 - accuracy: 0.0991\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.6179 - accuracy: 0.0997\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.3777 - accuracy: 0.1049\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.6123 - accuracy: 0.1076: 0s - loss: 237.5981 - accuracy\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.8235 - accuracy: 0.1059\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.1078 - accuracy: 0.1045\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.1618 - accuracy: 0.0990\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 235.0412 - accuracy: 0.1009\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.3773 - accuracy: 0.1086\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.9122 - accuracy: 0.1018\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.3163 - accuracy: 0.0964\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 239.1692 - accuracy: 0.1045\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.5792 - accuracy: 0.1059\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.5191 - accuracy: 0.1037\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.6314 - accuracy: 0.1021\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 235.7639 - accuracy: 0.1080\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.9901 - accuracy: 0.0989\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.9693 - accuracy: 0.1024\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 240.5513 - accuracy: 0.1030\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 240.0656 - accuracy: 0.1004\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.3905 - accuracy: 0.1054\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.4889 - accuracy: 0.1016\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 236.2348 - accuracy: 0.1006\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 236.3042 - accuracy: 0.1023\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.1051 - accuracy: 0.1006\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.5899 - accuracy: 0.1010\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.7125 - accuracy: 0.1016\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.0320 - accuracy: 0.1051\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.0073 - accuracy: 0.1044\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.3696 - accuracy: 0.1002\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.0020 - accuracy: 0.1063\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.0235 - accuracy: 0.1018\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.2372 - accuracy: 0.1049\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 237.3544 - accuracy: 0.1046\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 237.0202 - accuracy: 0.1055\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 239.0118 - accuracy: 0.1035\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 2ms/step - loss: 238.8944 - accuracy: 0.0995\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.7038 - accuracy: 0.1009\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 238.8173 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14be9bc50>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def loss_fn(subtypes, w_trues):\n",
    "#     bsize = len(subtypes)\n",
    "#     total_loss = tf.convert_to_tensor(0.0)\n",
    "#     for i in tf.range(bsize):\n",
    "#         subtype = subtypes[i]\n",
    "#         w_true = w_trues[i]\n",
    "#         total_loss += tf.reduce_sum(subtype)\n",
    "#     return total_loss\n",
    "#     d = w_true.shape[0]\n",
    "#     W_pred = tf.reshape(tf.transpose(tf.tile(subtype, (d*d, 1))), (2, d, d)) * W_k\n",
    "#     return tf.reduce_sum(tf.squared_difference(tf.zeros(W_true.shape), W_true))\n",
    "\n",
    "# var_list_fn = lambda: model.trainable_weights\n",
    "# for inval, outval in zip(e_n[:80], subtypes[:80]):\n",
    "#   opt.minimize(loss_fn, var_list_fn)\n",
    "\n",
    "def loss(x_true, w_pred):\n",
    "    d = float(tf.shape(w_pred)[1])\n",
    "    n = float(tf.shape(x_true)[0])\n",
    "    l1_lambda = 1.0\n",
    "    alpha = 1.0e2\n",
    "    rho = 1.0e2\n",
    "    h = tf.linalg.trace(tf.linalg.expm(w_pred * w_pred)) - d\n",
    "    x_prime = tf.matmul(x_true, w_pred)\n",
    "    mse = tf.square(tf.linalg.norm(x_true - x_prime))\n",
    "    return 0.5 / n * mse \\\n",
    "            + l1_lambda * tf.norm(w_pred, ord=1) \\\n",
    "            + alpha * h + 0.5 * rho * h * h\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "metrics = ['accuracy']\n",
    "loss_fn = 'mse'\n",
    "\n",
    "model.compile(loss=loss, \n",
    "             optimizer=opt, \n",
    "             metrics = metrics)\n",
    "model.fit(e_n[:800], X_n[:800], batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x14c1a8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "mse| pred: 6.162416797637318, baseline: 6.159427318412488\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(e_n[900:901])\n",
    "y_true = W_n[900:901][0]\n",
    "print(f\"mse| pred: {np.mean(np.sum(np.square(y_pred-y_true)))}, baseline: {np.mean(np.sum(np.square(np.zeros(y_pred.shape)-y_true)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.13535693e-35, -8.60812849e-36,  2.13837075e+00,\n",
       "          3.50283206e-01],\n",
       "        [ 9.71582528e-36, -2.89748366e-35,  1.29655131e-09,\n",
       "          9.97875122e-06],\n",
       "        [-4.65190533e-05, -6.65372729e-01, -4.83426849e-18,\n",
       "         -1.61679171e-04],\n",
       "        [ 2.49212723e-35,  2.00855970e+00, -1.53988469e+00,\n",
       "          1.20172888e-35]],\n",
       "\n",
       "       [[ 1.58590230e-35,  6.94585722e-36, -1.22245669e+00,\n",
       "         -1.96326649e+00],\n",
       "        [ 1.04076594e-36,  2.92742174e-35, -9.10344744e-10,\n",
       "          1.26473733e-05],\n",
       "        [ 1.07025277e-04, -1.72486925e+00,  5.93750285e-18,\n",
       "          2.78525258e-04],\n",
       "        [-2.26224921e-35,  1.42876434e+00,  2.68954694e-01,\n",
       "          1.35458505e-36]]], dtype=float32)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y_pred, cmap='hot', interpolation='nearest')\n",
    "plt.show()\n",
    "plt.imshow(y_true, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_k_pred = explainer.trainable_variables[0].numpy()\n",
    "plt.imshow(W_k_pred[1], cmap='hot', interpolation='nearest')\n",
    "plt.show()\n",
    "plt.imshow(W_k[1], cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.1807475e-36,  2.7086915e-37,  2.1984136e-01, -9.7040731e-01],\n",
       "       [ 4.7636650e-36,  4.2766542e-36,  3.6743997e-11,  1.1502136e-05],\n",
       "       [ 4.1131778e-05, -1.2701867e+00,  1.3148005e-18,  8.9611669e-05],\n",
       "       [-2.2191007e-36,  1.6775833e+00, -5.0730819e-01,  5.9304809e-36]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnotears_dl",
   "language": "python",
   "name": "cnotears_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
